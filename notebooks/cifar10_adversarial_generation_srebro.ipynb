{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import glob\n",
    "import numpy as np\n",
    "import imageio\n",
    "import itertools\n",
    "import foolbox as fb\n",
    "import foolbox.ext.native as fbn\n",
    "import time\n",
    "import torchvision\n",
    "from model_robust import return_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation attack from existing validation images\n",
    "import eagerpy as ep\n",
    "import numpy as np\n",
    "\n",
    "class PrecomputedSamplesAttack:\n",
    "    \"\"\"This is a helper attack that makes it straight-forward to choose initialisation points\n",
    "       for boundary-type attacks from a given data set. All it does is to store samples and\n",
    "       the predicted responses of a given model in order to select suitable adversarial images\n",
    "       from the given data set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        \n",
    "    def feed(self, inputs):\n",
    "        response = self.model.forward(inputs).argmax(1)\n",
    "        \n",
    "        for k in range(len(inputs)):\n",
    "            self.labels.append(int(response[k]))\n",
    "            self.samples.append(inputs[k])\n",
    "\n",
    "    def __call__(self, inputs, labels):\n",
    "        inputs = ep.astensor(inputs)\n",
    "        labels = ep.astensor(labels)\n",
    "        x = ep.zeros_like(inputs)\n",
    "        \n",
    "        for k in range(len(labels)):\n",
    "            while True:\n",
    "                idx = np.random.randint(len(self.labels))\n",
    "                if int(labels[k].numpy()) != self.labels[idx]:\n",
    "                    x.tensor[k] = self.samples[idx]\n",
    "                    break\n",
    "        \n",
    "        return x.tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data = {}\n",
    "\n",
    "metrics = ['L2']\n",
    "repetitions = 1\n",
    "step_scale = 1\n",
    "num_batches = 16\n",
    "\n",
    "BB_static = {'init_attack' : 'init_attack', 'steps' : int(step_scale * 1000)}\n",
    "BB_lr = [{'lr' : 1e-3}]\n",
    "\n",
    "\n",
    "\n",
    "full_attacks = [\n",
    "    {'L2': [(fbn.attacks.PGD,{'num_steps' : int(1000 * step_scale)}, [{'epsilon' : 8.0/255.0}])], 'Name': 'PGDLinf'},\n",
    "               #{'L2': [(fbn.attacks.L2BasicIterativeAttack,{'num_steps' : int(1000 * step_scale)}, [{'epsilon' : 2.0}])], 'Name': 'PGDL2'},\n",
    "               #{'L2': [(fbn.attacks.L2BrendelBethgeAttack, BB_static, BB_lr)],'Name': 'BBL2'},\n",
    "               #{'L2': [(fb.attacks.DecoupledDirectionNormL2Attack, {}, {'steps' : int(step_scale * 300), 'quantize' : False})], 'Name': 'DDNL2'},\n",
    "               #{'L2': [(fb.attacks.AdamL1BasicIterativeAttack, {'random_start' : True, 'iterations' : int(step_scale * 200), 'binary_search' : 10, 'epsilon' : 0.1, 'stepsize' : 0.01}, [{}], {'distance' : fb.distances.MeanAbsoluteDistance})], 'Name': 'PGDL1'},\n",
    "               #{'L2': [(fbn.attacks.LinfinityBrendelBethgeAttack, BB_static, BB_lr)], 'Name': 'BBLinf'}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# load model\n",
    "test_batch_size = 20\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=test_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesss = ['convlinearl1k3c32relu']\n",
    "\n",
    "for attacks in full_attacks:\n",
    "    for namm in namesss:\n",
    "        model_name = namm\n",
    "        resnet = return_model(model_name)\n",
    "        resnet = resnet.to(device)\n",
    "        resnet.eval();\n",
    "        checkpoint = torch.load('./cifar_resnet/ckpt_{}.pth'.format(model_name))\n",
    "        for i in range(checkpoint['epoch'],checkpoint['epoch']+1):\n",
    "            resnet.load_state_dict(checkpoint['net'])\n",
    "\n",
    "            # init foolbox models\n",
    "            fbn_model = fbn.models.PyTorchModel(resnet, bounds=[0.0, 1.0], device=device)\n",
    "            fb_model = fb.models.PyTorchModel(resnet, bounds=[0.0, 1.0], device=device, num_classes=10)   \n",
    "\n",
    "            for metric in metrics:\n",
    "                for attack in attacks[metric]:\n",
    "                    iteration = 0\n",
    "                    print(attack)\n",
    "                    if len(attack) == 3:\n",
    "                        Attack, static_kwargs, dynamic_kwargs = attack\n",
    "                        native = 'foolbox.ext.native' in Attack.__module__\n",
    "                        attack = Attack(fbn_model) if native else Attack(fb_model)\n",
    "                    else:\n",
    "                        Attack, static_kwargs, dynamic_kwargs, init_kwargs = attack\n",
    "                        native = 'foolbox.ext.native' in Attack.__module__\n",
    "                        attack = Attack(fbn_model) if native else Attack(fb_model, **init_kwargs)\n",
    "\n",
    "                    name = str(attack.__class__).split('.')[-1].split(\"'\")[0]\n",
    "                    if metric == 'L2':\n",
    "                        bbattack = fbn.attacks.L2BrendelBethgeAttack(fbn_model)\n",
    "\n",
    "                    if native:\n",
    "                        model = fbn_model\n",
    "                        print(\"Native\")\n",
    "                    else:\n",
    "                        model = fb_model\n",
    "                    # create init attack if necessary\n",
    "                    if 'init_attack' in static_kwargs.keys():\n",
    "                        init_attack = PrecomputedSamplesAttack(fbn_model)\n",
    "\n",
    "                        for batch in testloader:\n",
    "                            inputs, labels = batch\n",
    "                            inputs = inputs.to(device)\n",
    "                            labels = labels.to(device)\n",
    "\n",
    "                            out = init_attack.feed(inputs)\n",
    "\n",
    "                        static_kwargs['init_attack'] = init_attack         \n",
    "\n",
    "\n",
    "                # perform attack with different arguments\n",
    "                    img = []\n",
    "                    for kwarg in dynamic_kwargs:\n",
    "                        kwargs = {**kwarg, **static_kwargs}\n",
    "                        print(kwarg)\n",
    "                        images = []\n",
    "                        for b, batch in enumerate(testloader):\n",
    "                            if b == 100:\n",
    "                                break\n",
    "                            check = time.time()\n",
    "                            inputs, labels = batch\n",
    "                            inputs = inputs.to(device)\n",
    "                            labels = labels.to(device)\n",
    "                            if not native:\n",
    "                                inputs = inputs.data.cpu().numpy()\n",
    "                                labels = labels.data.cpu().numpy()\n",
    "                            adversarials = attack(\n",
    "                                inputs,\n",
    "                                labels,\n",
    "                                **kwargs\n",
    "                            )\n",
    "\n",
    "                            out = model.forward(adversarials)\n",
    "                            is_adv = out.argmax(1) != labels\n",
    "                            out_x = model.forward(inputs)\n",
    "                            is_cor = out_x.argmax(1) == labels\n",
    "\n",
    "                            # check if adversarial\n",
    "                            if native:\n",
    "                                out = out.data.cpu().numpy()\n",
    "                                adversarials = adversarials.data.cpu().numpy()\n",
    "                                inputs = inputs.data.cpu().numpy()\n",
    "                                labels = labels.data.cpu().numpy()\n",
    "                            output = out.argmax(1)\n",
    "                            for k in range(len(inputs)):\n",
    "                                if is_adv[k] and is_cor[k]:\n",
    "                                    x0 = inputs[k]\n",
    "                                    x = adversarials[k]\n",
    "                                    images.append([x, x0,labels[k],output[k]])\n",
    "                                else:\n",
    "                                    x0 = inputs[k]\n",
    "                                    x = np.zeros((3,32,32))\n",
    "                                    images.append([x,x0,labels[k],None])\n",
    "                            if b % 10 == 0:\n",
    "                                print(model_name,'{}/{}'.format(i,checkpoint['epoch']), 'Time: ', time.time() - check)\n",
    "                        img.append(images)\n",
    "\n",
    "\n",
    "                    np.save(\"./cifar_resnet/{}_{}_adversarial.npy\".format(model_name, attacks['Name']),img)\n",
    "\n",
    "                    # delete model to free memory\n",
    "                    del fb_model\n",
    "                    del fbn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaBackprop():\n",
    "    \"\"\"\n",
    "        Produces gradients generated with vanilla back propagation from the image\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "        # Hook the first layer to get the gradient\n",
    "        self.hook_layers() \n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.module._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class):\n",
    "        # Forward\n",
    "        input_image.requires_grad_(True)\n",
    "        scores = self.model(input_image)\n",
    "        # Zero grads\n",
    "        self.model.zero_grad()\n",
    "        # Target for backprop\n",
    "        score_max_index = scores.argmax()\n",
    "        score_max = scores[0,score_max_index]\n",
    "        dc_dx = torch.autograd.grad(score_max, input_image)[0]\n",
    "\n",
    "        return dc_dx[0,...].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "test_batch_size = 1\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=test_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nam in namesss:\n",
    "    resnet = return_model(nam) \n",
    "    resnet = torch.nn.DataParallel(resnet)\n",
    "    resnet = resnet.to(device)\n",
    "    resnet.eval()\n",
    "    checkpoint = torch.load('./cifar_resnet/ckpt_{}.pth'.format(nam))\n",
    "    for i in range(checkpoint['epoch'],checkpoint['epoch']+1):\n",
    "        lss = []\n",
    "        resnet.load_state_dict(checkpoint['net'])\n",
    "        VBP = VanillaBackprop(resnet)\n",
    "        for b, batch in enumerate(testloader):\n",
    "            if b == 2000:\n",
    "                break\n",
    "            inputs.requires_grad = True\n",
    "            inputs = inputs.to(device)\n",
    "            out_x = resnet.forward(inputs)\n",
    "            cat = out_x.argmax(1)\n",
    "            vanilla_grads = VBP.generate_gradients(inputs, int(cat.cpu().numpy()))\n",
    "            vanilla_grads = (vanilla_grads - vanilla_grads.mean())/vanilla_grads.std()\n",
    "            vanilla_grads = np.abs(vanilla_grads)\n",
    "            vanilla_grads = vanilla_grads - vanilla_grads.min()\n",
    "            vanilla_grads = vanilla_grads/(vanilla_grads.max() - vanilla_grads.min())\n",
    "            lss.append(vanilla_grads)\n",
    "\n",
    "        np.save(\"./cifar_resnet/{}_saliency.npy\".format(nam),lss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = {}\n",
    "import numpy as np\n",
    "for mm in namesss:\n",
    "    a = np.load(\"./cifar_resnet/{}_PGDLinf_adversarial.npy\".format(mm), allow_pickle=True)\n",
    "    a = a[0]\n",
    "    distance = []\n",
    "    for i in range(a.shape[0]):\n",
    "        adv = a[i,0]\n",
    "        original = a[i,1]\n",
    "        adv_cls = a[i,3]\n",
    "        if adv_cls != None:\n",
    "            dist = np.linalg.norm((adv-original).flatten(), ord=2)\n",
    "            distance.append(dist)\n",
    "    distances[mm] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model,          Mean Norm,       Std Norm')\n",
    "for key in distances.keys():\n",
    "    mean_value = np.array(distances[key]).mean()\n",
    "    std_value = np.array(distances[key]).std()\n",
    "    print(key, mean_value, std_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = {}\n",
    "import numpy as np\n",
    "for mm in namesss:\n",
    "    a = np.load(\"./cifar_resnet/{}_PGDLinf_adversarial.npy\".format(mm), allow_pickle=True)\n",
    "    checkpoint = torch.load('./cifar_resnet/ckpt_{}.pth'.format(mm))\n",
    "    #images.append([x,x0,labels[k],None])\n",
    "    a = a[0]\n",
    "    distance = 0\n",
    "    for i in range(a.shape[0]):\n",
    "        adv = a[i,0]\n",
    "        original = a[i,1]\n",
    "        adv_cls = a[i,3]\n",
    "        if adv_cls != None:\n",
    "            distance = distance + 1\n",
    "    distances[mm] = distance/a.shape[0]\n",
    "for key in distances.keys():\n",
    "    print(key, distances[key]*100/checkpoint['acc'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
