{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, classes=10, kernel = 3, channels=3):\n",
    "        super(Net, self).__init__()\n",
    "        self.kernel = kernel\n",
    "        self.channels = channels\n",
    "        self.conv = nn.Conv2d(3,self.channels,self.kernel,1) \n",
    "        self.pad = math.ceil((32 - (32 - self.kernel + 1))/2)\n",
    "        self.linear = nn.Linear(self.channels*(32 - self.kernel + 1 + self.pad*2)*(32 - self.kernel + self.pad*2 + 1),10)\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.pad(x,(self.pad,self.pad,self.pad,self.pad),'circular')\n",
    "        x = self.conv(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class Net3(nn.Module):\n",
    "    def __init__(self, classes=10, kernel = 3, channels=3):\n",
    "        super(Net3, self).__init__()\n",
    "        self.kernel = kernel\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,self.channels,self.kernel,1) \n",
    "        self.pad1 = math.ceil((32 - (32 - self.kernel + 1))/2)\n",
    "        self.output1 = int((32 - self.kernel + 1 + self.pad1*2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(self.channels, self.channels, self.kernel,1) \n",
    "        self.pad2 = math.ceil((self.output1 - (self.output1 - self.kernel + 1))/2)\n",
    "        self.output2 = int((self.output1 - self.kernel + 1 + self.pad2*2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(self.channels, self.channels, self.kernel,1) \n",
    "        self.pad3 = math.ceil((self.output2 - (self.output2 - self.kernel + 1))/2)\n",
    "        self.output3 = int((self.output2 - self.kernel + 1 + self.pad3*2))\n",
    "        \n",
    "        self.linear = nn.Linear(self.channels*(self.output3 - self.kernel + 1 + self.pad3*2)*(self.output3 - self.kernel + self.pad3*2 + 1),10)\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.pad(x,(self.pad1,self.pad1,self.pad1,self.pad1),'circular')\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.pad(x,(self.pad2,self.pad2,self.pad2,self.pad2),'circular')\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.pad(x,(self.pad3,self.pad3,self.pad3,self.pad3),'circular')\n",
    "        x = self.conv3(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "posible_models = ['fclinearl3', 'fclinearl1','convlinearl1k3c3', 'convlinearl3k3c3','convlinearl1k11c3','convlinearl3k11c3','convlinearl1k32c3',\n",
    "                 'convlinearl3k32c3','convlinearl1k3c8','convlinearl1k3c32','convlinearl3k3c8','convlinearl3k3c32']\n",
    "\n",
    "def return_model(name='fclinearl1'):\n",
    "    if name == 'fclinearl3':\n",
    "        model = nn.Sequential(nn.Flatten(), nn.Linear(3*32*32,3*32*32),nn.Linear(3*32*32,3*32*32), nn.Linear(3*32*32,3*32*32), nn.Linear(3*32*32,10))\n",
    "    elif name == 'fclinearl1':\n",
    "        model = nn.Sequential(nn.Flatten(),nn.Linear(3*32*32,3*32*32), nn.Linear(3*32*32,10))\n",
    "    elif name == 'convlinearl1k3c3':\n",
    "        model = Net(kernel=3,channels=3)\n",
    "    elif name == 'convlinearl3k3c3':\n",
    "        model = Net3(kernel=3,channels=3)\n",
    "    elif name == 'convlinearl1k11c3':\n",
    "        model = Net(kernel=11,channels=3)\n",
    "    elif name == 'convlinearl3k11c3':\n",
    "        model = Net3(kernel=11, channels=3)\n",
    "    elif name == 'convlinearl1k32c3':\n",
    "        model = Net(kernel=32, channels=3)\n",
    "    elif name == 'convlinearl3k32c3':\n",
    "        model = Net3(kernel=32, channels=3)\n",
    "    elif name == 'convlinearl1k3c8':\n",
    "        model = Net(kernel=3,channels=8)\n",
    "    elif name == 'convlinearl1k3c32':\n",
    "        model = Net(kernel=3, channels=32)\n",
    "    elif name == 'convlinearl3k3c8':\n",
    "        model = Net3(kernel=3, channels=8)\n",
    "    elif name == 'convlinearl3k3c32':\n",
    "        model = Net3(kernel=3, channels=32)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n",
      "\n",
      "Epoch: 0\n",
      "0 391 Loss: 2.307 | Acc: 13.281% (17/128)\n",
      "100 391 Loss: 1.936 | Acc: 32.758% (4235/12928)\n",
      "200 391 Loss: 1.874 | Acc: 34.958% (8994/25728)\n",
      "300 391 Loss: 1.841 | Acc: 36.215% (13953/38528)\n",
      "99 100 Loss: 1.737 | Acc: 39.820% (3982/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "0 391 Loss: 1.736 | Acc: 42.969% (55/128)\n",
      "100 391 Loss: 1.723 | Acc: 41.136% (5318/12928)\n",
      "200 391 Loss: 1.740 | Acc: 40.749% (10484/25728)\n",
      "300 391 Loss: 1.737 | Acc: 40.737% (15695/38528)\n",
      "99 100 Loss: 1.724 | Acc: 41.230% (4123/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "0 391 Loss: 1.707 | Acc: 37.500% (48/128)\n",
      "100 391 Loss: 1.702 | Acc: 42.041% (5435/12928)\n",
      "200 391 Loss: 1.699 | Acc: 41.931% (10788/25728)\n",
      "300 391 Loss: 1.706 | Acc: 41.697% (16065/38528)\n",
      "99 100 Loss: 1.737 | Acc: 39.740% (3974/10000)\n",
      "\n",
      "Epoch: 3\n",
      "0 391 Loss: 1.555 | Acc: 45.312% (58/128)\n",
      "100 391 Loss: 1.667 | Acc: 43.038% (5564/12928)\n",
      "200 391 Loss: 1.686 | Acc: 42.557% (10949/25728)\n",
      "300 391 Loss: 1.685 | Acc: 42.499% (16374/38528)\n",
      "99 100 Loss: 1.736 | Acc: 40.350% (4035/10000)\n",
      "\n",
      "Epoch: 4\n",
      "0 391 Loss: 1.711 | Acc: 39.844% (51/128)\n",
      "100 391 Loss: 1.627 | Acc: 45.212% (5845/12928)\n",
      "200 391 Loss: 1.630 | Acc: 44.834% (11535/25728)\n",
      "300 391 Loss: 1.637 | Acc: 44.594% (17181/38528)\n",
      "99 100 Loss: 1.711 | Acc: 41.500% (4150/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "0 391 Loss: 1.732 | Acc: 45.312% (58/128)\n",
      "100 391 Loss: 1.619 | Acc: 45.614% (5897/12928)\n",
      "200 391 Loss: 1.621 | Acc: 45.138% (11613/25728)\n",
      "300 391 Loss: 1.628 | Acc: 44.941% (17315/38528)\n",
      "99 100 Loss: 1.712 | Acc: 41.120% (4112/10000)\n",
      "\n",
      "Epoch: 6\n",
      "0 391 Loss: 1.562 | Acc: 52.344% (67/128)\n",
      "100 391 Loss: 1.614 | Acc: 45.336% (5861/12928)\n",
      "200 391 Loss: 1.625 | Acc: 44.811% (11529/25728)\n",
      "300 391 Loss: 1.625 | Acc: 44.856% (17282/38528)\n",
      "99 100 Loss: 1.724 | Acc: 40.620% (4062/10000)\n",
      "\n",
      "Epoch: 7\n",
      "0 391 Loss: 1.735 | Acc: 38.281% (49/128)\n",
      "100 391 Loss: 1.628 | Acc: 44.972% (5814/12928)\n",
      "200 391 Loss: 1.634 | Acc: 44.788% (11523/25728)\n",
      "300 391 Loss: 1.628 | Acc: 45.035% (17351/38528)\n",
      "99 100 Loss: 1.732 | Acc: 40.470% (4047/10000)\n",
      "\n",
      "Epoch: 8\n",
      "0 391 Loss: 1.638 | Acc: 42.969% (55/128)\n",
      "100 391 Loss: 1.598 | Acc: 46.241% (5978/12928)\n",
      "200 391 Loss: 1.600 | Acc: 46.102% (11861/25728)\n",
      "300 391 Loss: 1.606 | Acc: 45.920% (17692/38528)\n",
      "99 100 Loss: 1.717 | Acc: 40.930% (4093/10000)\n",
      "\n",
      "Epoch: 9\n",
      "0 391 Loss: 1.507 | Acc: 42.188% (54/128)\n",
      "100 391 Loss: 1.600 | Acc: 45.916% (5936/12928)\n",
      "200 391 Loss: 1.598 | Acc: 46.288% (11909/25728)\n",
      "300 391 Loss: 1.603 | Acc: 45.977% (17714/38528)\n",
      "99 100 Loss: 1.717 | Acc: 41.160% (4116/10000)\n",
      "\n",
      "Epoch: 10\n",
      "0 391 Loss: 1.617 | Acc: 48.438% (62/128)\n",
      "100 391 Loss: 1.599 | Acc: 46.047% (5953/12928)\n",
      "200 391 Loss: 1.601 | Acc: 45.938% (11819/25728)\n",
      "300 391 Loss: 1.602 | Acc: 45.917% (17691/38528)\n",
      "99 100 Loss: 1.719 | Acc: 40.920% (4092/10000)\n",
      "\n",
      "Epoch: 11\n",
      "0 391 Loss: 1.581 | Acc: 44.531% (57/128)\n",
      "100 391 Loss: 1.601 | Acc: 46.233% (5977/12928)\n",
      "200 391 Loss: 1.599 | Acc: 46.374% (11931/25728)\n",
      "300 391 Loss: 1.604 | Acc: 46.073% (17751/38528)\n",
      "99 100 Loss: 1.718 | Acc: 40.900% (4090/10000)\n",
      "\n",
      "Epoch: 12\n",
      "0 391 Loss: 1.425 | Acc: 53.906% (69/128)\n",
      "100 391 Loss: 1.599 | Acc: 46.310% (5987/12928)\n",
      "200 391 Loss: 1.603 | Acc: 46.098% (11860/25728)\n",
      "300 391 Loss: 1.596 | Acc: 46.291% (17835/38528)\n",
      "99 100 Loss: 1.718 | Acc: 41.160% (4116/10000)\n",
      "\n",
      "Epoch: 13\n",
      "0 391 Loss: 1.634 | Acc: 50.000% (64/128)\n",
      "100 391 Loss: 1.578 | Acc: 46.380% (5996/12928)\n",
      "200 391 Loss: 1.591 | Acc: 46.327% (11919/25728)\n",
      "300 391 Loss: 1.593 | Acc: 46.493% (17913/38528)\n",
      "99 100 Loss: 1.719 | Acc: 40.890% (4089/10000)\n",
      "\n",
      "Epoch: 14\n",
      "0 391 Loss: 1.718 | Acc: 37.500% (48/128)\n",
      "100 391 Loss: 1.609 | Acc: 45.885% (5932/12928)\n",
      "200 391 Loss: 1.599 | Acc: 46.377% (11932/25728)\n",
      "300 391 Loss: 1.601 | Acc: 46.195% (17798/38528)\n",
      "99 100 Loss: 1.719 | Acc: 40.980% (4098/10000)\n",
      "\n",
      "Epoch: 15\n",
      "0 391 Loss: 1.593 | Acc: 49.219% (63/128)\n",
      "100 391 Loss: 1.582 | Acc: 46.983% (6074/12928)\n",
      "200 391 Loss: 1.593 | Acc: 46.405% (11939/25728)\n",
      "300 391 Loss: 1.599 | Acc: 46.288% (17834/38528)\n",
      "99 100 Loss: 1.718 | Acc: 41.120% (4112/10000)\n",
      "\n",
      "Epoch: 16\n",
      "0 391 Loss: 1.550 | Acc: 51.562% (66/128)\n",
      "100 391 Loss: 1.604 | Acc: 45.761% (5916/12928)\n",
      "200 391 Loss: 1.598 | Acc: 46.020% (11840/25728)\n",
      "300 391 Loss: 1.597 | Acc: 46.260% (17823/38528)\n",
      "99 100 Loss: 1.719 | Acc: 41.040% (4104/10000)\n",
      "\n",
      "Epoch: 17\n",
      "0 391 Loss: 1.515 | Acc: 46.875% (60/128)\n",
      "100 391 Loss: 1.601 | Acc: 46.101% (5960/12928)\n",
      "200 391 Loss: 1.601 | Acc: 46.140% (11871/25728)\n",
      "300 391 Loss: 1.592 | Acc: 46.346% (17856/38528)\n",
      "99 100 Loss: 1.719 | Acc: 41.090% (4109/10000)\n",
      "\n",
      "Epoch: 18\n",
      "0 391 Loss: 1.557 | Acc: 52.344% (67/128)\n",
      "100 391 Loss: 1.590 | Acc: 46.496% (6011/12928)\n",
      "200 391 Loss: 1.589 | Acc: 46.626% (11996/25728)\n",
      "300 391 Loss: 1.591 | Acc: 46.514% (17921/38528)\n",
      "99 100 Loss: 1.719 | Acc: 41.040% (4104/10000)\n",
      "\n",
      "Epoch: 19\n",
      "0 391 Loss: 1.453 | Acc: 47.656% (61/128)\n",
      "100 391 Loss: 1.603 | Acc: 46.225% (5976/12928)\n",
      "200 391 Loss: 1.598 | Acc: 46.288% (11909/25728)\n",
      "300 391 Loss: 1.593 | Acc: 46.486% (17910/38528)\n",
      "99 100 Loss: 1.719 | Acc: 41.090% (4109/10000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "#parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "#arser.add_argument('--resume', '-r', action='store_true',\n",
    "#                    help='resume from checkpoint')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "args = {}\n",
    "args['resume'] = False\n",
    "args['lr'] = 0.01\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "posible_models = ['fclinearl3', 'fclinearl1','convlinearl1k3c3', 'convlinearl3k3c3','convlinearl1k11c3','convlinearl3k11c3','convlinearl1k32c3',\n",
    "                 'convlinearl3k32c3','convlinearl1k3c8','convlinearl1k3c32','convlinearl3k3c8','convlinearl3k3c32']\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "name = 'convlinearl1k3c32'\n",
    "net = return_model(name)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if args['resume']:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=args['lr'],\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "lambda1 = lambda epoch: 0.3**((epoch)//4)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR()\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda1])\n",
    "\n",
    "def train(epoch, name):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        #if epoch == 0 and batch_idx == 0:\n",
    "        if batch_idx%30 == 0:\n",
    "            torch.save(net.state_dict(), './cifar_resnet/ckpt_{}_{}_{}.pth'.format(name,epoch, batch_idx+1))\n",
    "        #torch.save(net.state_dict(), './cifar_resnet/ckpt_fc_{}_{}.pth'.format(epoch, batch_idx))\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if batch_idx%100 == 0:\n",
    "            print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'%(train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "def test(epoch,name):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('cifar_resnet'):\n",
    "            os.mkdir('cifar_resnet')\n",
    "        torch.save(state, './cifar_resnet/ckpt_{}.pth'.format(name))\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+20):\n",
    "    train(epoch,name)\n",
    "    test(epoch,name)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
